{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbb03a7-9a9f-4f81-aa94-3f92b8b78493",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bilateral Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf4dd8c-47ed-44c3-97c7-485e4515d19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd /tf/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f8a6930-1279-4b3f-981d-8e45c09c4f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcb975a-f1d2-419e-bb35-9fdd4d193817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install deepface==0.0.73 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f49a72-6040-40d9-b072-b5fdbaecf13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install opencv-python==4.5.5.62 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625a0912-7adf-4f6f-a8cc-7bde3a8f04c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc302f-d7ad-48b3-9012-3ca386e6db58",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19e8ff1-5b79-43b0-bc49-9b24dfa5c757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, classification_report, precision_score, accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import create_base_race_df, create_evaluation_dataset, verify_faces\n",
    "from preprocessing import read_this\n",
    "from skimage.restoration import denoise_bilateral\n",
    "\n",
    "import cv2\n",
    "\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d199dd0e-912c-44c8-a088-c4e5598f825d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "667856e0-04d8-4b5e-81cb-652e39065d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilateral_denoising(img):  \n",
    "    img = np.array(Image.open(img))\n",
    "    return cv2.bilateralFilter(img, 15, 75, 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9110d95c-47d5-4671-98eb-57e25a5ccfc3",
   "metadata": {},
   "source": [
    "## Bilateral Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb895bc-53f4-43c9-aef4-343d648bb5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vgg_face = DeepFace.build_model(\"VGG-Face\")\n",
    "\n",
    "facenet512 = DeepFace.build_model(\"Facenet512\")\n",
    "\n",
    "arcface = DeepFace.build_model(\"ArcFace\")\n",
    "\n",
    "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7534b79-f8e7-401e-b22c-1f54eeed739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_method = bilateral_denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c7869-b35f-4c21-9b99-0de147a29ba9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation concept\n",
    "\n",
    "Frame as binary classification problem and use AUROC as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10c864c-3c85-4f2c-89c1-2723ae844da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_face_target_folder = \"vgg_face_bilateral_denoising\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a15e382-fdda-4bcf-b237-dee8ccd7222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "facenet_target_folder = \"facenet_bilateral_denoising\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc36aee3-7bf2-4419-abcd-7ba7113e15e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_target_folder = \"arcface_bilateral_denoising\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e53d5c-5716-45ec-aa1f-16bc71b39d7f",
   "metadata": {},
   "source": [
    "## VGG-Face\n",
    "\n",
    "### African"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99939433-3ea3-4c44-a1bf-66382193bece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(1,6):\n",
    "        data = pd.read_pickle(f'data/val_data/African/result_dict{i}.pickle')\n",
    "        results = verify_faces(df = data,\n",
    "                        model = vgg_face, \n",
    "                        face_count=7000,\n",
    "                        preprocessing = preprocessing_method)\n",
    "        with open(f\"results/{vgg_face_target_folder}/African/result_dict{i}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f5c09-16a1-48c0-abf9-5a0aff94a904",
   "metadata": {},
   "source": [
    "### Asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7514c6-07b8-4d81-b2c5-8bfadcc5de01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(1,6):\n",
    "        data = pd.read_pickle(f'data/val_data/Asian/result_dict{i}.pickle')\n",
    "        results = verify_faces(df = data,\n",
    "                        model = vgg_face, \n",
    "                        face_count=7000,\n",
    "                        preprocessing = preprocessing_method)\n",
    "        with open(f\"results/{vgg_face_target_folder}/Asian/result_dict{i}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db464f0-0b6c-4faf-9ea2-482efab3e853",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Indian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c071d4-540e-40be-a2d9-bbb43817ba46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(1,6):\n",
    "        data = pd.read_pickle(f'data/val_data/Indian/result_dict{i}.pickle')\n",
    "        results = verify_faces(df = data,\n",
    "                        model = vgg_face, \n",
    "                        face_count=7000,\n",
    "                        preprocessing = preprocessing_method)\n",
    "        with open(f\"results/{vgg_face_target_folder}/Indian/result_dict{i}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0847948-66e5-4d7f-b1f7-7c70bd18e59b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Caucasian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63050723-c7bf-4752-9522-e31d3fc4ddc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(1,6):\n",
    "        data = pd.read_pickle(f'data/val_data/Caucasian/result_dict{i}.pickle')\n",
    "        results = verify_faces(df = data,\n",
    "                        model = vgg_face, \n",
    "                        face_count=7000,\n",
    "                        preprocessing = preprocessing_method)\n",
    "        with open(f\"results/{vgg_face_target_folder}/Caucasian/result_dict{i}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc11c96-f80a-43af-8616-de1595a8b4f4",
   "metadata": {},
   "source": [
    "## Facenet512\n",
    "\n",
    "### African"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af48abd-bfb8-4ed1-87ed-f1604f5cf7bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(1,6):\n",
    "        data = pd.read_pickle(f'data/val_data/African/result_dict{i}.pickle')\n",
    "        results = verify_faces(df = data,\n",
    "                        model = facenet512, \n",
    "                        face_count=7000,\n",
    "                        preprocessing = preprocessing_method)\n",
    "        with open(f\"results/{facenet_target_folder}/African/result_dict{i}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f00ea-d3cb-4f5b-a733-41a33ef148de",
   "metadata": {},
   "source": [
    "### Asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4daa9b-614e-495d-9fae-5aa0f5a84e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(1,6):\n",
    "        data = pd.read_pickle(f'data/val_data/Asian/result_dict{i}.pickle')\n",
    "        results = verify_faces(df = data,\n",
    "                        model = facenet512, \n",
    "                        face_count=7000,\n",
    "                        preprocessing = preprocessing_method)\n",
    "        with open(f\"results/{facenet_target_folder}/Asian/result_dict{i}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a35cb-257d-43f1-b8cc-0dcaf5e2a668",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Indian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788e344-7a4b-4ec9-ab50-cc87ae1146fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(1,6):\n",
    "        data = pd.read_pickle(f'data/val_data/Indian/result_dict{i}.pickle')\n",
    "        results = verify_faces(df = data,\n",
    "                        model = facenet512, \n",
    "                        face_count=7000,\n",
    "                        preprocessing = preprocessing_method)\n",
    "        with open(f\"results/{facenet_target_folder}/Indian/result_dict{i}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd3964-625a-41be-a2a2-f603f0679d2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Caucasian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1954a48-124c-430e-b248-f840f36ea8e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(1,6):\n",
    "        data = pd.read_pickle(f'data/val_data/Caucasian/result_dict{i}.pickle')\n",
    "        results = verify_faces(df = data,\n",
    "                        model = facenet512, \n",
    "                        face_count=7000,\n",
    "                        preprocessing = preprocessing_method)\n",
    "        with open(f\"results/{facenet_target_folder}/Caucasian/result_dict{i}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61b7d2-ab5e-4052-bfb1-16c4d587e768",
   "metadata": {},
   "source": [
    "## ArcFace\n",
    "\n",
    "### African"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ef216-3e62-4846-824f-4c89997b026e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(1,6):\n",
    "        data = pd.read_pickle(f'data/val_data/African/result_dict{i}.pickle')\n",
    "        results = verify_faces(df = data,\n",
    "                        model = arcface, \n",
    "                        face_count=7000,\n",
    "                        preprocessing = preprocessing_method)\n",
    "        with open(f\"results/{arcface_target_folder}/African/result_dict{i}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb135594-b8bf-4dd5-8106-9f21017cd15a",
   "metadata": {},
   "source": [
    "### Asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f92f6-09bd-47f1-af6e-656f4cb770c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(1,6):\n",
    "        data = pd.read_pickle(f'data/val_data/Asian/result_dict{i}.pickle')\n",
    "        results = verify_faces(df = data,\n",
    "                        model = arcface, \n",
    "                        face_count=7000,\n",
    "                        preprocessing = preprocessing_method)\n",
    "        with open(f\"results/{arcface_target_folder}/Asian/result_dict{i}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ae4ac-3e4a-46aa-8ed7-24e8784a7af0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Indian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecafa475-d613-4fde-bd8d-1a776134c883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(1,6):\n",
    "        data = pd.read_pickle(f'data/val_data/Indian/result_dict{i}.pickle')\n",
    "        results = verify_faces(df = data,\n",
    "                        model = arcface, \n",
    "                        face_count=7000,\n",
    "                        preprocessing = preprocessing_method)\n",
    "        with open(f\"results/{arcface_target_folder}/Indian/result_dict{i}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0561298c-2f43-4847-a5cb-5dccf91dda59",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Caucasian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd4f916f-013b-421d-80f5-66bd7f4b5b34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 8min 42s, sys: 5min 37s, total: 1h 14min 20s\n",
      "Wall time: 51min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(1,6):\n",
    "        data = pd.read_pickle(f'data/val_data/Caucasian/result_dict{i}.pickle')\n",
    "        results = verify_faces(df = data,\n",
    "                        model = arcface, \n",
    "                        face_count=7000,\n",
    "                        preprocessing = preprocessing_method)\n",
    "        with open(f\"results/{arcface_target_folder}/Caucasian/result_dict{i}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(results, file)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m89"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
